# Amazon S3 Bucket and Storage Classes

**Amazon S3** is an Object Storage built to store and retrieve any data from anywhere. It is known to be a promising, stable, and highly scalable online storage solution.

## What is Amazon S3 Bucket?

Amazon Simple Storage Service (S3) is a storage that can be maintained and accessed over the Internet. Amazon S3 provides a web service that can be used to store and retrieve an unlimited amount of data. It is global by default and bucket are region specified.

S3 in Amazon has two entities called buckets and objects. Objects are stored inside buckets.

By default, the maximum number of buckets that can be created per account is 100. For additional buckets, one can submit a request for a service limit increase.

![image](https://user-images.githubusercontent.com/17270996/141608847-29bec412-9770-4eee-8e31-660955fd4e08.png)

## Key Features of S3 Bucket

* Users get 99.99% durability.
* S3 provides Encryption to the data that you store. In two ways Client-Side Encryption and Server-Side Encryption
* Multiple copies are maintained to enable the regeneration of data in case of data corruption.
* S3 is Highly Scalable since it automatically scales your storage according to your requirement.
* only pay for the storage you use.

## Steps To Create AWS S3 Bucket

**Step 1:** Sign in to AWS Management Console

**Step 2:** Under Storage & Content Delivery, select S3 to open the Amazon S3 console.

**Step 3:** From the Amazon S3 console, choose Create Bucket.

![image](https://user-images.githubusercontent.com/17270996/141608922-cd07a31b-1087-4739-a655-359c76bc2691.png)

**Step 4:** Type a bucket name in Bucket Name (name must be unique) and choose the desired Region. Scroll down and click on Create Bucket.

![image](https://user-images.githubusercontent.com/17270996/141608934-f2c2940f-6b23-4bf3-8999-c9ec702ba87d.png)

**Step 5:** Now that the bucket has been created, go inside your bucket and click on Upload to upload an object.

![image](https://user-images.githubusercontent.com/17270996/141608954-9e6d3bbb-9c07-4020-ab25-fc8ffda7143f.png)

**Step 6:** Click on Add files and select the file to upload and click on Upload

![image](https://user-images.githubusercontent.com/17270996/141608967-d2a0a4d2-b05c-4574-9944-1f7827c0fece.png)

Now if you go to the image (here k21.png), you’ll find a URL. If you try to access these files outside the premises of AWS through URL it will deny your request.

![image](https://user-images.githubusercontent.com/17270996/141609020-2695c884-3f01-4683-8fed-0f107449132f.png)

Consider an example in which we have created an S3 bucket “mandemo” with default permissions. when we try to access it shows the below error page:

![image](https://user-images.githubusercontent.com/17270996/141609049-04b6e491-9c76-4ab6-b526-24636601ccca.png)

Therefore, we need to change the default setting and grant file public access.

# Steps To Grant S3 Bucket Public Access  

**Step 1:** Go to your Amazon S3 console.

**Step 2:** Click on the name of the Amazon S3 bucket from the list. If it’s still in its default access state, it should say “Buckets and objects not public”.

![image](https://user-images.githubusercontent.com/17270996/141609078-55119276-44da-4bdc-9138-0b3d46e8dad4.png)

**Step 3:** Go to the Permissions tab. The first sub-tab, which is open by default, is Block Public Access, and the “Block all public access” option will be On. Click on the Edit button.

![image](https://user-images.githubusercontent.com/17270996/141609096-01d29d17-4a1c-42db-b836-634d16a938c5.png)

* Uncheck the “Block all public access” option, and then click on the Save changes button. It will ask to confirm the change but typing in the word “confirm”.
* Go to the file which needs public access and move to the Object Actions drop-down menu and click on “Make Public“. You will see another window and click on Make Public

![image](https://user-images.githubusercontent.com/17270996/141609127-87fb6cc4-910e-4784-8def-6bc0606ce887.png)

**Step 4:** Now go to the object again and you can find the file’s Object URL.

![image](https://user-images.githubusercontent.com/17270996/141609135-77338d9c-ac84-4531-8033-c970666f8a7f.png)

You can now go to the browser and open this URL or share it with someone else.

![image](https://user-images.githubusercontent.com/17270996/141609186-e0dc57d0-74be-4ffc-9d67-5d5a2c37e093.png)

# S3 Storage Class

Amazon S3 offers a wide range of storage classes for different use cases. These provide us the storage for data that is rarely used, doesn’t require instant access, long-term archive, digital preservation, and many more. All Amazon S3 storage classes have a high level of reliability and support SSL data encryption during transmission, but differ by their cost.

![image](https://user-images.githubusercontent.com/17270996/141609261-9819165f-0917-46d5-bf0d-02732b8ab56b.png)

## Types of S3 Storage Classes
The different storage classes provided are:

* S3 Standard
* S3 Standard-IA
* S3 Intelligent-Tiering
* S3 One Zone-IA
* S3 Glacier
* S3 Glacier Deep Archive
* S3 Outposts
* Let’s see the various storage classes in S3 and the key points of these classes.

### S3 Standard

S3 Standard is the default storage class if none of the storage class is specified during upload. It is ideal for frequently accessed data because it provides low latency and high availability. It has a wide range of use cases from cloud applications and web services, websites hosting, big data analytics, mobile gaming, and content distribution. It is the most expensive storage class among all others.

Key Points: 

* High Availability and low latency
* Data is stored in multiple locations. So it is resilient against events that affect an entire Availability Zone
* The durability of 99.999999999% and availability of 99.99% availability over a given year
* Most expensive storage class among all others.

### S3 Standard-IA

S3 Standard-Infrequent Access is optimized for long-lived and less frequently accessed data but requires rapid access whenever required. Similar to S3 Standard, it also offers high durability, low latency, and high throughput but has a low per GB storage price and per GB retrieval fee. The S3 Standard-IA is ideal for backups, long-term storage, and as a data store for disaster recovery

Key Points: 

* High Availability and Low Latency (Same as S3 Standard)
* Offers greater availability and resiliency than the OneZone-IA storage.
* The durability of 99.999999999% and availability of 99.99% availability over a given year
* Less expensive than S3 Standard storage but you will be charged a retrieval fee hence suitable for infrequently accessed data.

### S3 Intelligent-Tiering

S3 Intelligent-Tiering optimizes costs by automatically moving data to the most cost-effective access tier, without performance impact or operational overhead. It moves objects that have not been accessed for 30 consecutive days to the infrequent access tier. If the object is accessed then it is automatically moved back to the frequent access tier. No retrieval fees or additional tiering fees are using the S3 Intelligent-Tiering storage class. It is ideal for storing long-lived data where the access patterns are unknown.

Key Points: 

* Low latency and high throughput performance
* Automatically moves the data between two access tiers. (Infrequent Access and Frequent Access)
* The durability of 99.999999999% and availability of 99.99% availability over a given year
* Small monthly monitoring and auto-tiering fee

### S3 One Zone-IA

S3 One Zone- Infrequent Access is for the data that is accessed less frequently but available for millisecond access. Since the other S3 storage class store data in a minimum of 3 Availability Zones (AZ), S3 One Zone-IA stores data in only one AZ which makes the costs 20% lesser than the S3 Standard-IA. It offers the same high durability, high throughput, and low latency. It can be considered as a good choice for storing secondary backup copies or easily re-creatable data if an AZ fails.

Key Points: 

* Low Latency and High throughput performance
* The durability of 99.999999999% and availability of 99.5% availability over a given year
* Data will be lost if the Availability Zone where the data is stored is destroyed.
* Suitable for larger objects greater than 128 KB kept for at least 30 days (charged minimum for 30 days)

### S3 Glacier

S3 Glacier is a low-cost storage class for data archiving where data access is infrequent. It provides a configurable retrieval time for the data from minutes to hours. This storage class uses a very low-cost Glacier storage service but the objects are still managed through S3.

Key Points: 

* Low-cost design for long-term archiving
* Data will be available in case of entire Availability Zone destruction
* The durability of 99.999999999% and availability of 99.9% availability over a given year
* It has a minimum storage duration period of 90 days.

### S3 Glacier Deep Archive

The S3 Glacier Deep Archive provides the lowest-cost storage class and supports long-term retention and digital preservation for data that may be accessed only once or twice in a year. It is ideal for those industries which store data for 5-10 years or longer like healthcare, finance, etc. It can also be used for backup and disaster recovery.

Key Points: 

* Lowest cost storage option in S3
* The durability of 99.999999999% and availability of 99.9% availability over a given year
* Retrieval costs can be reduced by using bulk retrieval
* It has a minimum storage duration period of 180 days

### S3 Outposts
S3 on Outposts provides object storage to our on-premises AWS outposts environment. S3 on Outposts makes it easy to store, retrieve, secure, control access, tag, and report on the data. It is ideal for workloads with local data residency requirements, and to satisfy demanding performance needs by keeping data close to on-premises.

Key Points: 

* S3 Object compatibility and bucket management is through S3 SDK
* For durable and redundant storage of data on Outposts
* S3 on Outposts will give users 48TB or 96TB of S3 storage capacity, with up 100 buckets on each Outpost.
* Hope the blog will help you in creating & understanding the concept behind an S3 bucket on AWS. Now it’s your turn to post your doubts in the comment section.














